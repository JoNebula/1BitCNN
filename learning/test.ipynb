{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3abe3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591723b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"woBN_qat_bnn_model.pth\")\n",
    "npy_dict = {\n",
    "        \"conv1w\": state_dict[\"conv1.weight\"].sign().cpu().numpy(),\n",
    "        \"conv2w\": state_dict[\"conv2.weight\"].sign().cpu().numpy(),\n",
    "        \"conv3w\": state_dict[\"conv3.weight\"].sign().cpu().numpy(),\n",
    "        \"fc1w\": state_dict[\"fc1.weight\"].sign().cpu().numpy(),\n",
    "        \"fc1b\": state_dict[\"fc1.bias\"].cpu().numpy(),\n",
    "    }\n",
    "np.save(\"qat_bnn_model.npy\", npy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f0d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === threshold Í≥ÑÏÇ∞ Ìï®Ïàò ===\n",
    "def bn_to_threshold(bn_layer):\n",
    "    gamma = bn_layer.weight.detach().cpu().numpy()\n",
    "    beta = bn_layer.bias.detach().cpu().numpy()\n",
    "    mean = bn_layer.running_mean.detach().cpu().numpy()\n",
    "    var = bn_layer.running_var.detach().cpu().numpy()\n",
    "    eps = bn_layer.eps\n",
    "\n",
    "    alpha = gamma / np.sqrt(var + eps)\n",
    "    bias = beta - alpha * mean\n",
    "    threshold = -bias / alpha\n",
    "    return threshold\n",
    "\n",
    "def threshold_activation(x, threshold):\n",
    "    th = torch.from_numpy(threshold).to(x.device)\n",
    "    if x.dim() == 4:\n",
    "        th = th.view(1, -1, 1, 1)\n",
    "    elif x.dim() == 2:\n",
    "        th = th.view(1, -1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported input shape: {x.shape}\")\n",
    "    return (x > th).float() * 2 - 1\n",
    "\n",
    "# === Inference-only Binarized Î™®Îç∏ ===\n",
    "class BinarizedInferenceBNN(nn.Module):\n",
    "    def __init__(self, qat_model):\n",
    "        super().__init__()\n",
    "\n",
    "        # Binary weights\n",
    "        self.conv1_weight = qat_model.conv1.weight.data.sign()\n",
    "        self.conv2_weight = qat_model.conv2.weight.data.sign()\n",
    "        self.conv3_weight = qat_model.conv3.weight.data.sign()\n",
    "        self.fc1_weight   = qat_model.fc1.weight.data.sign()\n",
    "        self.fc1_bias     = qat_model.fc1.bias.data\n",
    "\n",
    "\n",
    "        # Thresholds from BatchNorm\n",
    "        #self.th1 = bn_to_threshold(qat_model.bn1)\n",
    "        #self.th2 = bn_to_threshold(qat_model.bn2)\n",
    "        #self.th3 = bn_to_threshold(qat_model.bn3)\n",
    "        #self.th_fc = bn_to_threshold(qat_model.bn_fc)\n",
    "\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.conv2d(x, self.conv1_weight, None, stride=1)\n",
    "        x = x.sign()\n",
    "        #x = threshold_activation(x, self.th1)\n",
    "\n",
    "        x = F.conv2d(x, self.conv2_weight, None, stride=1)\n",
    "        x = x.sign()\n",
    "        #x = threshold_activation(x, self.th2)\n",
    "\n",
    "        x = F.conv2d(x, self.conv3_weight, None, stride=1)\n",
    "        x = x.sign()\n",
    "        #x = threshold_activation(x, self.th3)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        #x = threshold_activation(x, self.th_fc)\n",
    "        x = F.linear(x, self.fc1_weight, self.fc1_bias)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b84f3087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-1., -1.,  1.],\n",
       "                        [ 1., -1.,  1.],\n",
       "                        [ 1.,  1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1., -1., -1.],\n",
       "                        [ 1., -1., -1.],\n",
       "                        [-1.,  1., -1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1., -1.,  1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [ 1.,  1., -1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1., -1., -1.],\n",
       "                        [ 1., -1.,  1.],\n",
       "                        [ 1.,  1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1., -1.,  1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [ 1., -1., -1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.,  1.,  1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [-1., -1., -1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.,  1., -1.],\n",
       "                        [ 1., -1., -1.],\n",
       "                        [-1., -1., -1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.,  1.,  1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [ 1.,  1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1., -1.,  1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [ 1., -1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1., -1.,  1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [ 1., -1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.,  1., -1.],\n",
       "                        [ 1., -1., -1.],\n",
       "                        [-1., -1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1., -1., -1.],\n",
       "                        [-1.,  1., -1.],\n",
       "                        [-1.,  1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1., -1., -1.],\n",
       "                        [ 1., -1.,  1.],\n",
       "                        [-1.,  1., -1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1., -1.,  1.],\n",
       "                        [-1.,  1., -1.],\n",
       "                        [ 1.,  1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.,  1., -1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [-1.,  1., -1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.,  1.,  1.],\n",
       "                        [-1.,  1., -1.],\n",
       "                        [ 1.,  1., -1.]]]], device='cuda:0')),\n",
       "             ('bn1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "                     device='cuda:0')),\n",
       "             ('bn1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('bn1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('bn1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "                     device='cuda:0')),\n",
       "             ('bn1.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[-1.,  1., -1.],\n",
       "                        [ 1., -1., -1.],\n",
       "                        [-1., -1., -1.]],\n",
       "              \n",
       "                       [[ 1., -1.,  1.],\n",
       "                        [ 1.,  1.,  1.],\n",
       "                        [ 1., -1., -1.]],\n",
       "              \n",
       "                       [[-1., -1.,  1.],\n",
       "                        [-1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.,  1., -1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [ 1., -1., -1.]],\n",
       "              \n",
       "                       [[ 1., -1., -1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [-1.,  1., -1.]],\n",
       "              \n",
       "                       [[-1., -1.,  1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [-1.,  1., -1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [ 1.,  1.,  1.]],\n",
       "              \n",
       "                       [[-1.,  1.,  1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [ 1.,  1.,  1.]],\n",
       "              \n",
       "                       [[ 1.,  1., -1.],\n",
       "                        [ 1., -1., -1.],\n",
       "                        [ 1.,  1., -1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.,  1.,  1.],\n",
       "                        [-1.,  1.,  1.],\n",
       "                        [ 1., -1., -1.]],\n",
       "              \n",
       "                       [[ 1.,  1., -1.],\n",
       "                        [-1.,  1.,  1.],\n",
       "                        [-1., -1., -1.]],\n",
       "              \n",
       "                       [[-1.,  1.,  1.],\n",
       "                        [ 1., -1.,  1.],\n",
       "                        [ 1.,  1., -1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1., -1., -1.],\n",
       "                        [ 1., -1.,  1.],\n",
       "                        [ 1.,  1.,  1.]],\n",
       "              \n",
       "                       [[-1., -1., -1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [-1.,  1., -1.]],\n",
       "              \n",
       "                       [[ 1., -1.,  1.],\n",
       "                        [ 1., -1.,  1.],\n",
       "                        [ 1., -1., -1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1., -1.,  1.],\n",
       "                        [ 1., -1., -1.],\n",
       "                        [ 1.,  1.,  1.]],\n",
       "              \n",
       "                       [[-1., -1., -1.],\n",
       "                        [ 1.,  1.,  1.],\n",
       "                        [-1.,  1.,  1.]],\n",
       "              \n",
       "                       [[-1.,  1., -1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [-1.,  1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.,  1., -1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [-1., -1., -1.]],\n",
       "              \n",
       "                       [[-1., -1., -1.],\n",
       "                        [-1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.]],\n",
       "              \n",
       "                       [[-1.,  1., -1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [ 1., -1., -1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.,  1.,  1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [ 1.,  1.,  1.]],\n",
       "              \n",
       "                       [[ 1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [-1., -1., -1.]],\n",
       "              \n",
       "                       [[-1., -1., -1.],\n",
       "                        [ 1.,  1.,  1.],\n",
       "                        [-1.,  1., -1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1., -1.,  1.],\n",
       "                        [-1.,  1., -1.],\n",
       "                        [ 1.,  1.,  1.]],\n",
       "              \n",
       "                       [[-1., -1., -1.],\n",
       "                        [-1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.]],\n",
       "              \n",
       "                       [[ 1.,  1., -1.],\n",
       "                        [ 1.,  1.,  1.],\n",
       "                        [-1.,  1.,  1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1., -1.,  1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [ 1.,  1., -1.]],\n",
       "              \n",
       "                       [[ 1., -1., -1.],\n",
       "                        [ 1., -1., -1.],\n",
       "                        [ 1., -1., -1.]],\n",
       "              \n",
       "                       [[ 1.,  1.,  1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [-1., -1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.,  1., -1.],\n",
       "                        [ 1.,  1.,  1.],\n",
       "                        [ 1., -1.,  1.]],\n",
       "              \n",
       "                       [[ 1.,  1., -1.],\n",
       "                        [ 1.,  1.,  1.],\n",
       "                        [ 1.,  1.,  1.]],\n",
       "              \n",
       "                       [[-1., -1.,  1.],\n",
       "                        [-1.,  1., -1.],\n",
       "                        [-1.,  1., -1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.,  1., -1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [ 1.,  1.,  1.]],\n",
       "              \n",
       "                       [[-1.,  1., -1.],\n",
       "                        [ 1.,  1.,  1.],\n",
       "                        [-1.,  1., -1.]],\n",
       "              \n",
       "                       [[-1.,  1., -1.],\n",
       "                        [ 1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.]]]], device='cuda:0')),\n",
       "             ('bn2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "                     device='cuda:0')),\n",
       "             ('bn2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('bn2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('bn2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "                     device='cuda:0')),\n",
       "             ('bn2.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('conv3.weight',\n",
       "              tensor([[[[-1., -1., -1.],\n",
       "                        [-1.,  1.,  1.],\n",
       "                        [ 1., -1., -1.]],\n",
       "              \n",
       "                       [[ 1., -1.,  1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [ 1., -1.,  1.]],\n",
       "              \n",
       "                       [[ 1.,  1.,  1.],\n",
       "                        [ 1.,  1.,  1.],\n",
       "                        [-1.,  1.,  1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1., -1., -1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [ 1., -1.,  1.]],\n",
       "              \n",
       "                       [[ 1.,  1.,  1.],\n",
       "                        [ 1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.]],\n",
       "              \n",
       "                       [[ 1.,  1., -1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [-1., -1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1., -1.,  1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [ 1.,  1.,  1.]],\n",
       "              \n",
       "                       [[ 1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [-1.,  1., -1.]],\n",
       "              \n",
       "                       [[ 1., -1., -1.],\n",
       "                        [-1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [ 1., -1.,  1.]],\n",
       "              \n",
       "                       [[-1., -1.,  1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [ 1., -1.,  1.]],\n",
       "              \n",
       "                       [[-1., -1.,  1.],\n",
       "                        [-1.,  1., -1.],\n",
       "                        [-1., -1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.,  1.,  1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [ 1.,  1.,  1.]],\n",
       "              \n",
       "                       [[ 1.,  1., -1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [-1., -1.,  1.]],\n",
       "              \n",
       "                       [[ 1., -1.,  1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [-1., -1., -1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.,  1., -1.],\n",
       "                        [-1.,  1., -1.],\n",
       "                        [ 1.,  1., -1.]],\n",
       "              \n",
       "                       [[-1.,  1., -1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [-1.,  1.,  1.]],\n",
       "              \n",
       "                       [[ 1., -1., -1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [ 1., -1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1., -1.,  1.],\n",
       "                        [-1.,  1., -1.],\n",
       "                        [ 1., -1., -1.]],\n",
       "              \n",
       "                       [[ 1., -1.,  1.],\n",
       "                        [-1.,  1.,  1.],\n",
       "                        [-1.,  1., -1.]],\n",
       "              \n",
       "                       [[ 1.,  1., -1.],\n",
       "                        [ 1., -1.,  1.],\n",
       "                        [ 1.,  1., -1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1., -1.,  1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [ 1.,  1., -1.]],\n",
       "              \n",
       "                       [[ 1.,  1.,  1.],\n",
       "                        [ 1., -1., -1.],\n",
       "                        [-1.,  1., -1.]],\n",
       "              \n",
       "                       [[ 1., -1.,  1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [ 1., -1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.,  1., -1.],\n",
       "                        [-1., -1.,  1.],\n",
       "                        [ 1., -1., -1.]],\n",
       "              \n",
       "                       [[ 1., -1., -1.],\n",
       "                        [-1.,  1., -1.],\n",
       "                        [-1.,  1., -1.]],\n",
       "              \n",
       "                       [[-1.,  1., -1.],\n",
       "                        [-1., -1., -1.],\n",
       "                        [-1.,  1., -1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1., -1., -1.],\n",
       "                        [-1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.]],\n",
       "              \n",
       "                       [[ 1.,  1., -1.],\n",
       "                        [ 1., -1., -1.],\n",
       "                        [-1.,  1., -1.]],\n",
       "              \n",
       "                       [[ 1.,  1.,  1.],\n",
       "                        [ 1., -1.,  1.],\n",
       "                        [-1., -1.,  1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1., -1.,  1.],\n",
       "                        [-1.,  1.,  1.],\n",
       "                        [-1., -1.,  1.]],\n",
       "              \n",
       "                       [[ 1., -1., -1.],\n",
       "                        [ 1.,  1., -1.],\n",
       "                        [-1., -1., -1.]],\n",
       "              \n",
       "                       [[-1.,  1.,  1.],\n",
       "                        [-1.,  1., -1.],\n",
       "                        [ 1., -1.,  1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1., -1.,  1.],\n",
       "                        [-1.,  1.,  1.],\n",
       "                        [ 1., -1., -1.]],\n",
       "              \n",
       "                       [[-1.,  1.,  1.],\n",
       "                        [ 1.,  1.,  1.],\n",
       "                        [ 1., -1.,  1.]],\n",
       "              \n",
       "                       [[-1.,  1.,  1.],\n",
       "                        [-1.,  1., -1.],\n",
       "                        [-1.,  1., -1.]]]], device='cuda:0')),\n",
       "             ('bn3.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "                     device='cuda:0')),\n",
       "             ('bn3.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('bn3.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('bn3.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "                     device='cuda:0')),\n",
       "             ('bn3.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('bn_fc.weight',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('bn_fc.bias',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('bn_fc.running_mean',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('bn_fc.running_var',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('bn_fc.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 1.,  1.,  1.,  ...,  1.,  1., -1.],\n",
       "                      [-1., -1., -1.,  ...,  1., -1., -1.],\n",
       "                      [ 1.,  1.,  1.,  ...,  1., -1.,  1.],\n",
       "                      ...,\n",
       "                      [-1., -1., -1.,  ..., -1., -1.,  1.],\n",
       "                      [ 1.,  1.,  1.,  ..., -1.,  1.,  1.],\n",
       "                      [ 1., -1.,  1.,  ..., -1., -1., -1.]], device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([-1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.], device='cuda:0'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict[\"conv1.weight\"] = state_dict[\"conv1.weight\"].sign()\n",
    "state_dict[\"conv2.weight\"] = state_dict[\"conv2.weight\"].sign()\n",
    "state_dict[\"conv3.weight\"] = state_dict[\"conv3.weight\"].sign()\n",
    "state_dict[\"fc1.weight\"] = state_dict[\"fc1.weight\"].sign()\n",
    "state_dict[\"fc1.bias\"] = state_dict[\"fc1.bias\"].sign()\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd818990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinarizedInferenceBNN(\n",
       "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bnn_learn import QATBNN  # ÏõêÎûò Î™®Îç∏ Ï†ïÏùò\n",
    "\n",
    "# 1. ÏõêÎûò ÌïôÏäµÏö© Î™®Îç∏ Ï†ïÏùò & Î°úÎìú\n",
    "qat_model = QATBNN()\n",
    "#state_dict = torch.load(\"best_qat_bnn_model.pth\", map_location='cpu')\n",
    "qat_model.load_state_dict(state_dict)\n",
    "qat_model.eval()\n",
    "\n",
    "# 2. Inference-only BNNÏúºÎ°ú Î≥ÄÌôò\n",
    "inference_model = BinarizedInferenceBNN(qat_model)\n",
    "inference_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e87f6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Accuracy (Binary-only): 93.62%\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data, target in test_loader:\n",
    "    data = (data).float()*2 - 1\n",
    "    output = inference_model(data)\n",
    "    pred = output.argmax(dim=1)\n",
    "    correct += (pred == target).sum().item()\n",
    "    total += target.size(0)\n",
    "\n",
    "print(f\"Inference Accuracy (Binary-only): {correct / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7554848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Binary Inference Accuracy: 96.27%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ‚úÖ Load your MNIST data\n",
    "mnist = np.load(\"mnist-original.npy\", allow_pickle=True)\n",
    "X = mnist.item().get(\"data\").T / 255.0  # shape: (70000, 784), normalize to [0, 1]\n",
    "y = mnist.item().get(\"label\")[0]        # shape: (70000,)\n",
    "\n",
    "# ‚úÖ Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).view(-1, 1, 28, 28)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# ‚úÖ Make test loader (Ïòà: ÎßàÏßÄÎßâ 1ÎßåÍ∞úÎ•º testÎ°ú ÏÇ¨Ïö©)\n",
    "test_dataset = TensorDataset(X_tensor[-10000:], y_tensor[-10000:])\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# ‚úÖ Load QAT model and convert to binary inference model\n",
    "qat_model = QATBNN()\n",
    "qat_model.load_state_dict(state_dict)#torch.load(\"best_qat_bnn_model.pth\", map_location=\"cpu\"))\n",
    "qat_model.eval()\n",
    "\n",
    "inference_model = BinarizedInferenceBNN(qat_model)\n",
    "inference_model.eval()\n",
    "\n",
    "# ‚úÖ Inference loop\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = inference_model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f\"üß† Binary Inference Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1742e7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))  # Ï†ÑÏ≤¥ figure ÌÅ¨Í∏∞\n",
    "\n",
    "plt.imshow(images[0,0].squeeze().numpy(), cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b7e2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this on pnyq..\n",
    "## NOTE:: This is a very unoptimized version \n",
    "## only use this as a template\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.signal import convolve2d\n",
    "from tqdm import trange\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "mnist = np.load(\"mnist-original.npy\", allow_pickle= True)\n",
    "\n",
    "X = mnist.item().get(\"data\").T / 255\n",
    "y = mnist.item().get(\"label\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a5d05a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 700/700 [16:02<00:00,  1.38s/it, accuracy=86.15%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Final Accuracy: 86.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "weights = np.load('qat_bnn_model.npy',allow_pickle=True)\n",
    "\n",
    "conv1w = weights.item().get('conv1w')\n",
    "conv2w = weights.item().get('conv2w')\n",
    "conv3w = weights.item().get('conv3w')\n",
    "fc3w = weights.item().get('fc1w')\n",
    "fc3b = weights.item().get('fc1b')\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "def avg_pool2d(x, kernel_size=2, stride=2):\n",
    "    batch_size, channels, height, width = x.shape\n",
    "\n",
    "    out_height = height // kernel_size\n",
    "    out_width = width // kernel_size\n",
    "    \n",
    "    x_summed = np.add.reduceat(np.add.reduceat(x, np.arange(0, height, stride), axis=2), \n",
    "                               np.arange(0, width, stride), axis=3)\n",
    "    \n",
    "    x_pooled = x_summed / (kernel_size * kernel_size)\n",
    "    \n",
    "    return x_pooled\n",
    "\n",
    "def feed_foward(X0):\n",
    "    ## unfortunately, I found no efficient implementation of 2D Conv without using pytorch \n",
    "    ## this code is VERY SLOW. Just use this to see the correctness of the results \n",
    "    X0 = X0.reshape(-1, 1, 28, 28)\n",
    "    X1 = np.zeros((batch_size, 16, 26, 26))  # Temporary buffer for X1\n",
    "    X2 = np.zeros((batch_size, 16, 24, 24))  # Temporary buffer for X2\n",
    "    X3 = np.zeros((batch_size, 32, 22, 22))  # Temporary buffer for X2\n",
    "    ## conv1 layer\n",
    "    for b in range(batch_size):\n",
    "        for co in range(16):\n",
    "            X1[b,co] = convolve2d(X0[b,0], conv1w[co, 0][::-1, ::-1], mode='valid')\n",
    "\n",
    "    ## ReLU        \n",
    "    X1 = np.sign(X1)\n",
    "    #X1[X1<0] = 0\n",
    "\n",
    "    ## conv2 layer\n",
    "    for b in range(batch_size):\n",
    "        for co in range(16):\n",
    "            for ci in range(16):\n",
    "                X2[b,co] += convolve2d(X1[b,ci], conv2w[co, ci][::-1, ::-1], mode='valid')    \n",
    "\n",
    "    X2 = np.sign(X2)\n",
    "    #X2[X2<0] = 0\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        for co in range(32):\n",
    "            for ci in range(16):\n",
    "                X3[b,co] += convolve2d(X2[b,ci], conv3w[co, ci][::-1, ::-1], mode='valid')    \n",
    "\n",
    "    X3 = np.sign(X3)\n",
    "    #X3[X3<0] = 0\n",
    "\n",
    "    A3 = avg_pool2d(X3)\n",
    "    A3 = A3.reshape(-1, 3872)\n",
    "    X3 = np.matmul(A3, fc3w.T) + fc3b\n",
    "\n",
    "    return X3\n",
    "            \n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "pbar = tqdm(range(len(X) // batch_size), desc=\"Evaluating\", dynamic_ncols=True)\n",
    "for idx in pbar:\n",
    "    xs = X[batch_size * idx : batch_size * idx + batch_size]\n",
    "    ys = y[batch_size * idx : batch_size * idx + batch_size]\n",
    "    outputs = feed_foward(xs)\n",
    "\n",
    "    predictions = np.argmax(outputs, axis=1)\n",
    "    correct += np.sum(predictions == ys)\n",
    "    total += len(ys)\n",
    "\n",
    "    acc = (correct / total) * 100\n",
    "    pbar.set_postfix(accuracy=f\"{acc:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Final Accuracy: {acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorProcessor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
